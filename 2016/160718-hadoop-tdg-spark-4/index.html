<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">






  
  
  <link rel="stylesheet" href="/lib/Han/dist/han.min.css?v=3.3">



















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.1.1',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="持久化回到本章开头的例子，我们可以把“年度-气温”的中间数据集缓存在内存中： 12scala&amp;gt; tuples.cache()res1: tuples.type = MappedRDD[4] at map at &amp;lt;console&amp;gt;:18 调用cache()不会立刻把RDD缓存到内存中，只是对这个RDD做一个标记，当Spark作业运行的时候，实际的缓存行为才会发生。因此我们首先强制运">
<meta name="keywords" content="hadoop,spark">
<meta property="og:type" content="article">
<meta property="og:title" content="翻译：Hadoop权威指南之Spark-4">
<meta property="og:url" content="https://qinm08.github.io/2016/160718-hadoop-tdg-spark-4/index.html">
<meta property="og:site_name" content="Key Memory">
<meta property="og:description" content="持久化回到本章开头的例子，我们可以把“年度-气温”的中间数据集缓存在内存中： 12scala&amp;gt; tuples.cache()res1: tuples.type = MappedRDD[4] at map at &amp;lt;console&amp;gt;:18 调用cache()不会立刻把RDD缓存到内存中，只是对这个RDD做一个标记，当Spark作业运行的时候，实际的缓存行为才会发生。因此我们首先强制运">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2016-08-19T10:21:32.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="翻译：Hadoop权威指南之Spark-4">
<meta name="twitter:description" content="持久化回到本章开头的例子，我们可以把“年度-气温”的中间数据集缓存在内存中： 12scala&amp;gt; tuples.cache()res1: tuples.type = MappedRDD[4] at map at &amp;lt;console&amp;gt;:18 调用cache()不会立刻把RDD缓存到内存中，只是对这个RDD做一个标记，当Spark作业运行的时候，实际的缓存行为才会发生。因此我们首先强制运">





  
  
  <link rel="canonical" href="https://qinm08.github.io/2016/160718-hadoop-tdg-spark-4/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>翻译：Hadoop权威指南之Spark-4 | Key Memory</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Key Memory</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://qinm08.github.io/2016/160718-hadoop-tdg-spark-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="秦铭">
      <meta itemprop="description" content="不忘初心，方得始终">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Key Memory">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">翻译：Hadoop权威指南之Spark-4

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-07-18 00:00:00" itemprop="dateCreated datePublished" datetime="2016-07-18T00:00:00+08:00">2016-07-18</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-08-19 18:21:32" itemprop="dateModified" datetime="2016-08-19T18:21:32+08:00">2016-08-19</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>回到本章开头的例子，我们可以把“年度-气温”的中间数据集缓存在内存中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; tuples.cache()</span><br><span class="line">res1: tuples.type = MappedRDD[4] at map at &lt;console&gt;:18</span><br></pre></td></tr></table></figure>
<p>调用cache()不会立刻把RDD缓存到内存中，只是对这个RDD做一个标记，当Spark作业运行的时候，实际的缓存行为才会发生。因此我们首先强制运行一个作业：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; tuples.reduceByKey((a, b) =&gt; Math.max(a, b)).foreach(println(_))</span><br><span class="line">INFO BlockManagerInfo: Added rdd_4_0 in memory on 192.168.1.90:64640</span><br><span class="line">INFO BlockManagerInfo: Added rdd_4_1 in memory on 192.168.1.90:64640</span><br><span class="line">(1950,22)</span><br><span class="line">(1949,111)</span><br></pre></td></tr></table></figure>
<p>关于BlockManagerInfo的日志显示，作为作业运行的一部分，RDD的分区会被保持在内存中。日志显示这个RDD的编号是4（在调用cache()方法之后的控制台输出中，也能看到这个信息），它包含两个分区，标签分别是0和1。如果在这个缓存的数据集上运行另一个作业，我们会看到这个RDD将从内存中加载。这次我们计算最低气温：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; tuples.reduceByKey((a, b) =&gt; Math.min(a, b)).foreach(println(_))</span><br><span class="line">INFO BlockManager: Found block rdd_4_0 locally</span><br><span class="line">INFO BlockManager: Found block rdd_4_1 locally</span><br><span class="line">(1949,78)</span><br><span class="line">(1950,-11)</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>这是在微小数据集上的简单示例，但是对于更大的作业，节省的时间将很可观。在MapReduce中，为了执行另一个计算，输入数据集必须再次从磁盘加载。即使中间数据可以作为输入（比如一个清洗后的数据集，无效行和不必要的字段都已移除），也不能改变“数据必须从磁盘加载”的事实，这是很慢的。Spark会把数据集缓存在一个遍布集群的内存高速缓存中，这就意味着任何基于此数据集的计算都会执行的非常快。</p>
<p>在对数据进行交互式探索时，这种效率是极其有用的。这也自然适合某些类型的算法，比如迭代算法，一次迭代计算的结果可以缓存在内存中，成为下次迭代计算的输入。这种算法也可以用MapReduce实现，每次迭代都是一个单独的MapReduce作业，因此每次迭代的结果必须写入磁盘，然后在下次迭代时再读回来。</p>
<blockquote>
<p>缓存的RDD只能被同一个应用中的作业获取。要在不同的应用之间共享数据集，第一个应用必须使用某个saveAs*()方法（saveAsTextFile()，saveAsHadoopFile()等等）来写到外部存储中，然后第二个应用使用SparkContext中的对应方法（textFile()，hadoopFile()等等）再次加载。同样的，当一个应用终止时，它缓存的所有RDD都被销毁，除非显式的保存下来，否则不能再次访问。</p>
</blockquote>
<h3 id="持久化级别"><a href="#持久化级别" class="headerlink" title="持久化级别"></a>持久化级别</h3><p>调用cache()会把RDD的每个分区持久化到执行器（executor）的内存中。如果执行器没有足够的内存来存储这个RDD分区，计算不会失败，相反该分区将会根据需要进行重算。对于带有很多转换操作的复杂程序，这是很昂贵的。因此Spark提供了不同类型的持久化行为供用户选择，在调用persist()时指定StorageLevel参数即可。</p>
<p>默认的持久化级别是MEMORY_ONLY，这种方式使用对象的常规内存表示。要使用更紧凑的表现形式，可以把分区中的元素序列化为字节数组（byte array）。这种级别是MEMORY_ONLY_SER，相比MEMORY_ONLY，这种级别会导致CPU的开销，如果序列化之后的RDD分区能够适应内存，而常规的内存表示不适合，那么这种开销就是值得的。MEMORY_ONLY_SER还会减轻垃圾回收的压力，因为每个RDD都以字节数组的形式存储，而不是很多的对象。</p>
<blockquote>
<p>在驱动程序的日志文件中，检查BlockManager相关的信息，可以看到一个RDD分区是否不适合内存。另外，每个驱动程序的SparkContext会在4040端口启动一个HTTP服务，提供关于运行环境以及正在运行的作业的有用信息，包括缓存的RDD分区的信息。</p>
</blockquote>
<p>默认情况下，使用常规的Java序列化框架来序列化RDD分区，不过Kryo序列化框架（下节讨论）通常是更好的选择，在大小和速度两方面都更优秀。如果把序列化后的分区进行压缩，可以节省更多的空间（再一次付出CPU的代价），设置spark.rdd.compress属性为true来启用压缩，属性spark.io.compression.codec是可选设置。</p>
<p>如果重算一个数据集非常昂贵，那么MEMORY_AND_DISK（如果数据集在内存中放不下，就写到磁盘上）或者MEMORY_AND_DISK_SER（如果序列化后的数据集在内存中放不下，就写到磁盘上）是合适的。</p>
<p>还有一些更高级的和实验中的持久化级别，用来在集群中的多个节点上复制分区，或者使用off-heap内存——更多细节，查看Spark文档。</p>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>在Spark中需要考虑序列化的两个方面：序列化数据和序列化函数（或闭包）。</p>
<h3 id="数据序列化"><a href="#数据序列化" class="headerlink" title="数据序列化"></a>数据序列化</h3><p>首先来看数据的序列化。默认情况下，Spark使用Java序列化框架在执行器之间的网络上传输数据，或者以序列化的形式来缓存数据。对程序员来说，Java的序列化很好理解，只需确定你使用的类实现了java.io.Serializable接口或者java.io.Externalizable接口，但从性能和大小的角度来看，这种方式的效率不高。</p>
<p>对于大多数的Spark程序，更好的选择是Kryo序列化框架。Kryo是一个高效的通用的Java序列化库。要使用Kryo，在驱动程序的SparkConf上设置spark.serializer属性如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conf.set(<span class="string">"spark.serializer"</span>,  <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>)</span><br></pre></td></tr></table></figure>
<p>Kryo不要求你的类实现特定接口，因此简单的Java对象不需要任何改动即可在RDD中使用。话虽如此，如果在使用一个类之前把它注册到Kryo会更加高效。这是因为Kryo会创建一个引用，指向那个序列化对象的类（一个对象对应一个引用），如果类已注册，该引用是个整数ID，如果类没有注册，该引用是类的全名。这个引导仅仅适用于你自己的类，Scala类和许多其他的框架类（比如Avro Generic或者Thrift类）已经由Spark注册了。</p>
<p>向Kryo注册类也很简单。创建一个KryoRegistrator的子类，覆盖registerClasses()方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomKryoRegistrator</span> <span class="keyword">extends</span> <span class="title">KryoRegistrator</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">registerClasses</span></span>(kryo: <span class="type">Kryo</span>) &#123;</span><br><span class="line">    kryo.register(classOf[<span class="type">WeatherRecord</span>])</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，在驱动程序中，把属性spark.kryo.registrator设置为你的KryoRegistrator实现类的完整类名：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conf.set(<span class="string">"spark.kryo.registrator"</span>, <span class="string">"CustomKryoRegistrator"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="函数序列化"><a href="#函数序列化" class="headerlink" title="函数序列化"></a>函数序列化</h3><p>通常，函数的序列化将”刚好工作”：在Scala中，函数都是可序列化的，使用标准Java序列化机制。这也是Spark向远程执行器节点发送函数时使用的方式。即使在本地模式下运行，Spark也会序列化函数。如果你在无意中引入了不可序列化的函数（比如，从一个非序列化类的方法转换过来的函数），你会在开发过程的早期阶段发现它。</p>
<h2 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h2><p>Spark程序经常需要访问一些数据，这些数据不是一个RDD的一部分。例如，下面的程序在一个map()操作中使用了一个查找表（lookup table）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lookup = <span class="type">Map</span>(<span class="number">1</span> -&gt; <span class="string">"a"</span>, <span class="number">2</span> -&gt; <span class="string">"e"</span>, <span class="number">3</span> -&gt; <span class="string">"i"</span>, <span class="number">4</span> -&gt; <span class="string">"o"</span>, <span class="number">5</span> -&gt; <span class="string">"u"</span>)</span><br><span class="line"><span class="keyword">val</span> result = sc.parallelize(<span class="type">Array</span>(<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)).map(lookup(_))</span><br><span class="line">assert(result.collect().toSet === <span class="type">Set</span>(<span class="string">"a"</span>, <span class="string">"e"</span>, <span class="string">"i"</span>))</span><br></pre></td></tr></table></figure>
<p>这段程序会正确工作（变量lookup被序列化为闭包的一部分，传递给map()），但是还有一个更高效的方式来达到同样的目的：使用广播变量。</p>
<h3 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h3><p>广播变量在序列化之后发送给每一个执行器，在那里缓存起来，因此后续的任务可以在需要时访问。这与普通的变量不同。普通的变量会序列化为闭包的一部分，然后在网络上传输，一个任务一次传输。广播变量的角色，与MapReduce中的分布式缓存相似，不过Spark内部的实现是把数据存储在内存中，仅当内存被耗尽时才写到磁盘。</p>
<p>广播变量的创建方法是，把需要广播的变量传递给SparkContext的broadcast()方法。T类型的变量被包装进Broadcast[T]，然后返回：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lookup: <span class="type">Broadcast</span>[<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">String</span>]] =</span><br><span class="line">    sc.broadcast(<span class="type">Map</span>(<span class="number">1</span> -&gt; <span class="string">"a"</span>, <span class="number">2</span> -&gt; <span class="string">"e"</span>, <span class="number">3</span> -&gt; <span class="string">"i"</span>, <span class="number">4</span> -&gt; <span class="string">"o"</span>, <span class="number">5</span> -&gt; <span class="string">"u"</span>))</span><br><span class="line"><span class="keyword">val</span> result = sc.parallelize(<span class="type">Array</span>(<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)).map(lookup.value(_))</span><br><span class="line">assert(result.collect().toSet === <span class="type">Set</span>(<span class="string">"a"</span>, <span class="string">"e"</span>, <span class="string">"i"</span>))</span><br></pre></td></tr></table></figure>
<p>在RDD的map()操作中，调用这个广播变量的value来访问它。</p>
<p>顾名思义，广播变量是单向传送的，从驱动到任务——没有办法更新一个广播变量，然后回传给驱动。为此，我们需要一个累加器。</p>
<h3 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h3><p>累加器是一个共享变量，和MapReduce中的计数器一样，任务只能对其增加。在作业完成以后，累加器的最终值可以在驱动程序中获取。下面的例子中，使用累加器计算一个整数RDD中的元素数量，同时使用reduce()操作对RDD中的值求和：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> count: <span class="type">Accumulator</span>[<span class="type">Int</span>] = sc.accumulator(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">val</span> result = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">  .map(i =&gt; &#123; count += <span class="number">1</span>; i &#125;)</span><br><span class="line">  .reduce((x, y) =&gt; x + y)</span><br><span class="line">assert(count.value === <span class="number">3</span>)</span><br><span class="line">assert(result === <span class="number">6</span>)</span><br></pre></td></tr></table></figure>
<p>第一行代码使用SparkContext的accumulator()方法，创建了一个累加器变量count。map()操作是一个恒等函数，副作用是增加count。当Spark作业的结果计算出来之后，累加器的值通过调用value来访问。</p>
<p>在这个例子中，我们使用一个Int作为累加器，但任何的数值类型都是可以的。Spark还提供了两种方法，一是使用累加器的结果类型与“被增量”的类型不同（参见SparkContext的accumulable()方法），二是可以累加可变集合中的值（通过accumulableCollection()）。</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          
            <a href="/tags/spark/" rel="tag"># spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/160717-hadoop-tdg-spark-3/" rel="next" title="翻译：Hadoop权威指南之Spark-3">
                <i class="fa fa-chevron-left"></i> 翻译：Hadoop权威指南之Spark-3
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/160721-hadoop-tdg-spark-5/" rel="prev" title="翻译：Hadoop权威指南之Spark-5">
                翻译：Hadoop权威指南之Spark-5 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">秦铭</p>
              <div class="site-description motion-element" itemprop="description">不忘初心，方得始终</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">10</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#持久化"><span class="nav-number">1.</span> <span class="nav-text">持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#持久化级别"><span class="nav-number">1.1.</span> <span class="nav-text">持久化级别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#序列化"><span class="nav-number">2.</span> <span class="nav-text">序列化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据序列化"><span class="nav-number">2.1.</span> <span class="nav-text">数据序列化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#函数序列化"><span class="nav-number">2.2.</span> <span class="nav-text">函数序列化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#共享变量"><span class="nav-number">3.</span> <span class="nav-text">共享变量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#广播变量"><span class="nav-number">3.1.</span> <span class="nav-text">广播变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#累加器"><span class="nav-number">3.2.</span> <span class="nav-text">累加器</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">秦铭</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.1.1</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.1"></script>

  <script src="/js/motion.js?v=7.1.1"></script>



  
  


  <script src="/js/affix.js?v=7.1.1"></script>

  <script src="/js/schemes/pisces.js?v=7.1.1"></script>




  
  <script src="/js/scrollspy.js?v=7.1.1"></script>
<script src="/js/post-details.js?v=7.1.1"></script>



  


  <script src="/js/next-boot.js?v=7.1.1"></script>


  

  

  

  


  


  




  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
