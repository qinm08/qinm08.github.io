<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>翻译：Hadoop权威指南之Spark-2 | Ming&#39;s Coding Life</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="本文翻译自O’Reilly出版Tom White所著《Hadoop: The Definitive Guide》第4版第19章，向作者致敬。该书英文第4版已于2015年4月出版，至今已近15个月，而市面上中文第3版还在大行其道。Spark一章是第4版新增的内容，笔者在学习过程中顺便翻译记录，由于笔者也在学习，并无实战经验，难免翻译不妥或出错，欢迎方家来信斧正。翻译纯属兴趣，不做商业用途。秦铭，Em">
<meta property="og:type" content="article">
<meta property="og:title" content="翻译：Hadoop权威指南之Spark-2">
<meta property="og:url" content="https://qinm08.github.io/2016/07/17/hadoop-the-definitive-guide-spark-2/index.html">
<meta property="og:site_name" content="Ming's Coding Life">
<meta property="og:description" content="本文翻译自O’Reilly出版Tom White所著《Hadoop: The Definitive Guide》第4版第19章，向作者致敬。该书英文第4版已于2015年4月出版，至今已近15个月，而市面上中文第3版还在大行其道。Spark一章是第4版新增的内容，笔者在学习过程中顺便翻译记录，由于笔者也在学习，并无实战经验，难免翻译不妥或出错，欢迎方家来信斧正。翻译纯属兴趣，不做商业用途。秦铭，Em">
<meta property="og:updated_time" content="2016-07-16T16:04:03.961Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="翻译：Hadoop权威指南之Spark-2">
<meta name="twitter:description" content="本文翻译自O’Reilly出版Tom White所著《Hadoop: The Definitive Guide》第4版第19章，向作者致敬。该书英文第4版已于2015年4月出版，至今已近15个月，而市面上中文第3版还在大行其道。Spark一章是第4版新增的内容，笔者在学习过程中顺便翻译记录，由于笔者也在学习，并无实战经验，难免翻译不妥或出错，欢迎方家来信斧正。翻译纯属兴趣，不做商业用途。秦铭，Em">
  
    <link rel="alternative" href="/atom.xml" title="Ming&#39;s Coding Life" type="application/atom+xml">
  
  
    <link rel="shortcut icon" type="image/x-icon" href="/css/images/blacktocat.png">
  

<!--
  <link href="//fonts.googleapis.com/css?family=Inconsolata:400,700|Open+Sans:700,400" rel="stylesheet" type="text/css">

  


-->

  <link rel="stylesheet" href="/css/style.css">

</head>

<body>
  <div id="container">
    <div id="wrap">
      <div id="header">
  <div id="header-outer" class="outer">
    <div id="header-inner" class="inner">
      <div id="header-title">
        <h1 id="logo-wrap">
          <a href="/" id="logo">Ming&#39;s Coding Life
          
              <span id="subtitle">不忘初心，方得始终</span>
          
          </a>
        </h1>
      </div>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://qinm08.github.io"></form>
      </div>
    </div>
  </div>
</div>
      <div class="outer">
        <section id="main"><article id="post-hadoop-the-definitive-guide-spark-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/17/hadoop-the-definitive-guide-spark-2/" class="article-date">
  <time datetime="2016-07-16T16:04:03.961Z" itemprop="datePublished">2016-07-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      翻译：Hadoop权威指南之Spark-2
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文翻译自O’Reilly出版Tom White所著《Hadoop: The Definitive Guide》第4版第19章，向作者致敬。该书英文第4版已于2015年4月出版，至今已近15个月，而市面上中文第3版还在大行其道。Spark一章是第4版新增的内容，笔者在学习过程中顺便翻译记录，由于笔者也在学习，并无实战经验，难免翻译不妥或出错，欢迎方家来信斧正。翻译纯属兴趣，不做商业用途。秦铭，Email地址<a href="mailto:qinm08@gmail.com" target="_blank" rel="external">qinm08@gmail.com</a>。</p>
<hr>
<h1 id="A-Scala-Standalone-Application"><a href="#A-Scala-Standalone-Application" class="headerlink" title="A Scala Standalone Application"></a>A Scala Standalone Application</h1><p>在Spark shell中运行了一个小程序之后，你可能想要把它打包成自包含应用，这样就可以多次运行了。</p>
<p>示例19-1. 使用Spark找出最高气温的Scala应用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">import org.apache.spark.SparkContext._</div><div class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</div><div class="line"></div><div class="line">object MaxTemperature &#123;</div><div class="line">    def main(args: Array[String]) &#123;</div><div class="line">        val conf = new SparkConf().setAppName(&quot;Max Temperature&quot;)</div><div class="line">        val sc = new SparkContext(conf)</div><div class="line">        sc.textFile(args(0))</div><div class="line">          .map(_.split(&quot;\t&quot;))</div><div class="line">          .filter(rec =&gt; (rec(1) != &quot;9999&quot; &amp;&amp; rec(2).matches(&quot;[01459]&quot;)))</div><div class="line">          .map(rec =&gt; (rec(0).toInt, rec(1).toInt))</div><div class="line">          .reduceByKey((a, b) =&gt; Math.max(a, b))</div><div class="line">          .saveAsTextFile(args(1))</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行独立程序时，没有shell为我们提供SparkContext，我们需要自己创建。我们用一个SparkConf来创建这个实例。SparkConf可以用来向应用中传递多个Spark属性，这里我们仅仅设置应用的名字。</p>
<p>还有一些别的微小变化。首先是我们使用命令行参数来指定输入和输出路径。另外还使用了方法链来避免为每一个RDD创建中间变量，这样程序更紧凑，如果需要的话，我们仍然可以在Scala IDE中查看每次转变（transformation）的类型信息。</p>
<blockquote>
<p>并非所有的Spark定义的transformation都可用于RDD类本身。在本例中，reduceByKey()（仅仅在键值对的RDD上起作用）实际上定义在PairRDDFunctions类中，但我们能用下面的import来让Scala隐含地把RDD[(Int, Int)]转为PairRDDFunctions：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">import org.apache.spark.SparkContext._</div></pre></td></tr></table></figure></p>
<p>这个import不同于Spark使用的隐式转型函数，因此理所当然地值得包含在程序中。</p>
</blockquote>
<p>这一次我们使用spark-submit来运行这个程序，把包含编译后的Scala程序的JAR包作为参数传入，接着传入命令行参数（输入输出路径）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">% spark-submit --class MaxTemperature --master local \</div><div class="line">spark-examples.jar input/ncdc/micro-tab/sample.txt output</div><div class="line">% cat output/part-*</div><div class="line">(1950,22)</div><div class="line">(1949,111)</div></pre></td></tr></table></figure>
<p>我们还指定了两个选项：–class 告诉Spark应用类的名字，–master 指定job的运行方式，local值告诉Spark在本地机器的单个JVM中运行，在“Executors and Cluster Managers”一节我们将会学到在集群中运行的选项。接下来，我们看看怎样用Java语言来使用Spark。</p>
<h1 id="A-Java-Example"><a href="#A-Java-Example" class="headerlink" title="A Java Example"></a>A Java Example</h1><p>Spark是使用Scala实现的，Scala是基于JVM的语言，可以和Java完美集成。同样的例子用Java来表达，很直接，也很啰嗦（使用Java 8的lambda表达式可以使这个版本更紧凑）。</p>
<p>示例19-2. 使用Spark找出最高气温的Java应用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxTemperatureSpark</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        <span class="keyword">if</span> (args.length != <span class="number">2</span>) &#123;</div><div class="line">            System.err.println(<span class="string">"Usage: MaxTemperatureSpark &lt;input path&gt; &lt;output path&gt;"</span>);</div><div class="line">            System.exit(-<span class="number">1</span>);</div><div class="line">        &#125;</div><div class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf();</div><div class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(<span class="string">"local"</span>, <span class="string">"MaxTemperatureSpark"</span>, conf);</div><div class="line">        JavaRDD&lt;String&gt; lines = sc.textFile(args[<span class="number">0</span>]);</div><div class="line">        JavaRDD&lt;String[]&gt; records = lines.map(<span class="keyword">new</span> Function&lt;String, String[]&gt;() &#123;</div><div class="line">            <span class="meta">@Override</span> <span class="keyword">public</span> String[] call(String s) &#123;</div><div class="line">                <span class="keyword">return</span> s.split(<span class="string">"\t"</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;);</div><div class="line">        JavaRDD&lt;String[]&gt; filtered = records.filter(<span class="keyword">new</span> Function&lt;String[], Boolean&gt;() &#123;</div><div class="line">            <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> Boolean <span class="title">call</span><span class="params">(String[] rec)</span> </span>&#123;</div><div class="line">                <span class="keyword">return</span> rec[<span class="number">1</span>] != <span class="string">"9999"</span> &amp;&amp; rec[<span class="number">2</span>].matches(<span class="string">"[01459]"</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;);</div><div class="line">        JavaPairRDD&lt;Integer, Integer&gt; tuples = filtered.mapToPair(</div><div class="line">            <span class="keyword">new</span> PairFunction&lt;String[], Integer, Integer&gt;() &#123;</div><div class="line">                <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> Tuple2&lt;Integer, Integer&gt; <span class="title">call</span><span class="params">(String[] rec)</span> </span>&#123;</div><div class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;Integer, Integer&gt;(</div><div class="line">                        Integer.parseInt(rec[<span class="number">0</span>]), Integer.parseInt(rec[<span class="number">1</span>]));</div><div class="line">                &#125;</div><div class="line">        &#125;);</div><div class="line">        JavaPairRDD&lt;Integer, Integer&gt; maxTemps = tuples.reduceByKey(</div><div class="line">            <span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</div><div class="line">                <span class="meta">@Override</span> <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer i1, Integer i2)</span> </span>&#123;</div><div class="line">                    <span class="keyword">return</span> Math.max(i1, i2);</div><div class="line">                &#125;</div><div class="line">        &#125;);</div><div class="line">        maxTemps.saveAsTextFile(args[<span class="number">1</span>]);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在Spark的Java API中，一个RDD由JavaRDD的实例表示，在键值对RDD的特殊情况下是JavaPairRDD 。这两个类都实现了JavaRDDLike接口，该接口中可以找到操作RDD的大多数方法。</p>
<p>运行这个程序和运行Scala版本一样，除了类名字是MaxTemperatureSpark 。</p>
<h1 id="A-Python-Example"><a href="#A-Python-Example" class="headerlink" title="A Python Example"></a>A Python Example</h1><p>Spark也支持Python语言，API叫做PySpark。由于Python语言有lambda表达式，例子程序非常接近Scala的版本。</p>
<p>示例19-3. 使用Spark找出最高气温的Python应用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">form pyspark <span class="keyword">import</span> SparkContext</div><div class="line"><span class="keyword">import</span> re, sys</div><div class="line"></div><div class="line">sc = SparkContext(<span class="string">"local"</span>, <span class="string">"Max Temperature"</span>)</div><div class="line">sc.textFile(sys.argv[<span class="number">1</span>]) \</div><div class="line">  .map(<span class="keyword">lambda</span> s: s.split(<span class="string">"\t"</span>)) \</div><div class="line">  .filter(<span class="keyword">lambda</span> rec: (rec[<span class="number">1</span>] != <span class="string">"9999"</span> <span class="keyword">and</span> re.match(<span class="string">"[01459]"</span>, rec[<span class="number">2</span>]))) \</div><div class="line">  .map(<span class="keyword">lambda</span> rec: (int(rec[<span class="number">0</span>]), int(rec[<span class="number">1</span>]))) \</div><div class="line">  .reduceByKey(max) \</div><div class="line">  .saveAsTextFile(sys.argv[<span class="number">2</span>])</div></pre></td></tr></table></figure></p>
<p>注意到在reduceByKey()的转变中，我们可以使用Python语言内建的max函数。</p>
<p>需要留意的重点是，这个程序是用CPython写的，Spark会创建一个Python子进程来执行用户的Python代码（在启动程序launcher和在集群上运行用户任务的executor上）。两个进程间使用socket通讯来传递RDD分区数据。</p>
<p>要运行这个程序，只需指定Python文件即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">% spark-submit --master local \</div><div class="line">  ch19-spark/src/main/python/MaxTemperature.py \</div><div class="line">  input/ncdc/micro-tab/sample.txt output</div></pre></td></tr></table></figure></p>
<p>还可以使用pyspark命令，以交互模式运行Spark和Python。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://qinm08.github.io/2016/07/17/hadoop-the-definitive-guide-spark-2/" data-id="ciqpd29fm0001g9slg4zxvqm3" class="article-share-link">Share</a>
      
        <a href="https://qinm08.github.io/2016/07/17/hadoop-the-definitive-guide-spark-2/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/">Java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Scala/">Scala</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/07/17/hadoop-the-definitive-guide-spark-1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">翻译：Hadoop权威指南之Spark-1</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          
            <aside id="sidebar">
    <div class="widget-wrap fixed">
    <h3 class="widget-title">Anchors</h3>

    <div class="widget">
        <ul class='toc'>
        <li><a class='anchor' href='#logo'>Title</a></li>
        <li><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#A-Scala-Standalone-Application"><span class="toc-number">1.</span> <span class="toc-text">A Scala Standalone Application</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#A-Java-Example"><span class="toc-number">2.</span> <span class="toc-text">A Java Example</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#A-Python-Example"><span class="toc-number">3.</span> <span class="toc-text">A Python Example</span></a></li></ol></li>
        <li><a class='anchor' href='#comments'>Comments</a></li> 
        </ul>
    </div>
</div>
</aside>
          
        
      </div>
      <div id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Ming Qin<br>
      <img src="/css/images/email.png" height="12" width="16"/> <a href="mailto:qinm08@gmail.com"> qinm08@gmail.com</a><br>
      <img src="/css/images/github.png" height="16" width="16"/> <a href="https://github.com/qinm08" target="_blank"> https://github.com/qinm08</a><br>
    </div>
  </div>
</div>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'qinm08';
  
  var disqus_url = 'https://qinm08.github.io/2016/07/17/hadoop-the-definitive-guide-spark-2/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<!--
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
-->



<script src="/js/script.js"></script>

  </div>
</body>
</html>